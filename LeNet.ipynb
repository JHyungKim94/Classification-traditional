{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LeNet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_gTPSYzcSA3l","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import numpy as np\n","import matplotlib.pyplot as mlt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9dSj9a5EWTVN","colab_type":"code","colab":{}},"source":["# Transform\n","transform = transforms.Compose([transforms.Resize((32, 32)),\n","                               transforms.ToTensor()])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FrfLwMezWTfF","colab_type":"code","colab":{}},"source":["# Data\n","trainset = torchvision.datasets.MNIST(root='./data', train = True, download = True, transform = transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size = 256, shuffle = True, num_workers=8)\n","\n","testset = torchvision.datasets.MNIST(root='./data', train = False, download = True, transform = transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size = 1024, shuffle = True, num_workers=8)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbVhoHwnYba7","colab_type":"code","colab":{}},"source":["# Network\n","\n","class LeNet(nn.Module):\n","    \"\"\"\n","    Input - 1x32x32\n","    C1 - 6@28x28 (5x5 kernel)\n","    tanh\n","    S2 - 6@14x14 (2x2 kernel, stride 2) Subsampling\n","    C3 - 16@10x10 (5x5 kernel, complicated shit)\n","    tanh\n","    S4 - 16@5x5 (2x2 kernel, stride 2) Subsampling\n","    C5 - 120@1x1 (5x5 kernel)\n","    F6 - 84\n","    tanh\n","    F7 - 10 (Output)\n","    \"\"\"\n","    def __init__(self):\n","      \n","      super(LeNet, self).__init__()\n","      '''\n","      self.conv= nn.Sequential(OrderedDict([\n","        ('c1', nn.Conv2d(1, 6, kernel_size=(5, 5))),\n","        ('relu1', F.relu()),\n","        ('s2', nn.MaxPool2d(kernel_size(2, 2), stride=2)),\n","        ('c3', nn.Conv2d(6, 16, kernel_size=(5, 5))),\n","        ('relu3', F.relu()),\n","        ('s4', nn.MaxPool2d(kernel_size(2, 2), stride=2)),\n","        ('c5', nn.Conv2d(16, 120, kernel_size=(5, 5))),\n","        ('relu5', F.relu())\n","      ]))\n","      \n","      self.fc = nn.Sequential(OrderedDict([\n","        ('fc6', nn.Linear(120, 84)),\n","        ('relu6', F.relu()),\n","        ('fc7', nn.Linear(84, 10)),\n","        ('sig7', nn.LogSoftmax(dim=-1))\n","      ]))\n","      '''\n","      \n","      self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5))\n","      self.conv2 = nn.Conv2d(6, 16, kernel_size=(5, 5))\n","      self.conv3 = nn.Conv2d(16, 120, kernel_size=(5, 5))\n","      \n","      self.pool = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n","      \n","      self.fc1 = nn.Linear(120, 84)\n","      self.fc2 = nn.Linear(84, 10)\n","      \n","      \n","    def forward(self, x):\n","      '''\n","      x = self.conv(x)\n","      x = x.view(x.size(0), -1)\n","      x = self.fc(x)\n","      return x\n","      '''\n","      x = self.pool(F.relu(self.conv1(x)))\n","      x = self.pool(F.relu(self.conv2(x)))\n","      x = F.relu(self.conv3(x))\n","      \n","      x = x.view(x.size(0), -1)\n","      x = F.relu(self.fc1(x))\n","      sf = nn.LogSoftmax(dim=-1)\n","      \n","      return sf(x)\n","      \n","model = LeNet()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IM1lKd69dwub","colab_type":"code","colab":{}},"source":["# Loss function & Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=2e-3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SO4w_BO5eW3d","colab_type":"code","outputId":"5b8d23f2-68a5-434a-93ea-03830ed95981","executionInfo":{"status":"ok","timestamp":1563210683768,"user_tz":-540,"elapsed":1286,"user":{"displayName":"‍김준형(학부/공과대학 컴퓨터과학)","photoUrl":"https://lh3.googleusercontent.com/-f1oQLB_ApQg/AAAAAAAAAAI/AAAAAAAAAAc/D-JiDiWykkA/s64/photo.jpg","userId":"16102798597323885397"}},"colab":{"base_uri":"https://localhost:8080/","height":177}},"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","model.to(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["LeNet(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=120, out_features=84, bias=True)\n","  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"eGNqNgv0epvx","colab_type":"code","outputId":"9c8b4440-acfe-4782-b832-59af71253cee","executionInfo":{"status":"ok","timestamp":1563210874162,"user_tz":-540,"elapsed":19445,"user":{"displayName":"‍김준형(학부/공과대학 컴퓨터과학)","photoUrl":"https://lh3.googleusercontent.com/-f1oQLB_ApQg/AAAAAAAAAAI/AAAAAAAAAAc/D-JiDiWykkA/s64/photo.jpg","userId":"16102798597323885397"}},"colab":{"base_uri":"https://localhost:8080/","height":941}},"source":["# Training\n","epochs = 2\n","\n","for epoch in range(epochs):\n","  print('\\n===> Epoch [%d/%d]' % (epoch+1, epochs))\n","  \n","  running_loss = 0.0\n","  \n","  for i, data in enumerate(trainloader,0):\n","    \n","    # Data Load\n","    inputs, labels = data\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    \n","    # Zero the parameter gradients\n","    optimizer.zero_grad()\n","    \n","    # Forward\n","    outputs = model(inputs)\n","    loss = criterion(outputs, labels)\n","    \n","    # Backward\n","    loss.backward()\n","    \n","    # Optimize\n","    optimizer.step()\n","    \n","    # Print statistics\n","    running_loss += loss.item()\n","    \n","    # Print every 2000 mini-batches\n","    if i % 10 == 0 :\n","      print('      - Iteration [%5d / %5d] --- Loss: %.3f' %\n","            (i, len(trainloader), running_loss / 2000))\n","      running_loss = 0.0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","===> Epoch [1/2]\n","      - Iteration [    0 /   235] --- Loss: 0.000\n","      - Iteration [   10 /   235] --- Loss: 0.003\n","      - Iteration [   20 /   235] --- Loss: 0.002\n","      - Iteration [   30 /   235] --- Loss: 0.003\n","      - Iteration [   40 /   235] --- Loss: 0.002\n","      - Iteration [   50 /   235] --- Loss: 0.002\n","      - Iteration [   60 /   235] --- Loss: 0.002\n","      - Iteration [   70 /   235] --- Loss: 0.002\n","      - Iteration [   80 /   235] --- Loss: 0.002\n","      - Iteration [   90 /   235] --- Loss: 0.002\n","      - Iteration [  100 /   235] --- Loss: 0.002\n","      - Iteration [  110 /   235] --- Loss: 0.003\n","      - Iteration [  120 /   235] --- Loss: 0.003\n","      - Iteration [  130 /   235] --- Loss: 0.002\n","      - Iteration [  140 /   235] --- Loss: 0.002\n","      - Iteration [  150 /   235] --- Loss: 0.003\n","      - Iteration [  160 /   235] --- Loss: 0.002\n","      - Iteration [  170 /   235] --- Loss: 0.002\n","      - Iteration [  180 /   235] --- Loss: 0.003\n","      - Iteration [  190 /   235] --- Loss: 0.002\n","      - Iteration [  200 /   235] --- Loss: 0.002\n","      - Iteration [  210 /   235] --- Loss: 0.002\n","      - Iteration [  220 /   235] --- Loss: 0.002\n","      - Iteration [  230 /   235] --- Loss: 0.002\n","\n","===> Epoch [2/2]\n","      - Iteration [    0 /   235] --- Loss: 0.000\n","      - Iteration [   10 /   235] --- Loss: 0.002\n","      - Iteration [   20 /   235] --- Loss: 0.002\n","      - Iteration [   30 /   235] --- Loss: 0.002\n","      - Iteration [   40 /   235] --- Loss: 0.002\n","      - Iteration [   50 /   235] --- Loss: 0.002\n","      - Iteration [   60 /   235] --- Loss: 0.003\n","      - Iteration [   70 /   235] --- Loss: 0.003\n","      - Iteration [   80 /   235] --- Loss: 0.003\n","      - Iteration [   90 /   235] --- Loss: 0.002\n","      - Iteration [  100 /   235] --- Loss: 0.002\n","      - Iteration [  110 /   235] --- Loss: 0.002\n","      - Iteration [  120 /   235] --- Loss: 0.002\n","      - Iteration [  130 /   235] --- Loss: 0.002\n","      - Iteration [  140 /   235] --- Loss: 0.002\n","      - Iteration [  150 /   235] --- Loss: 0.002\n","      - Iteration [  160 /   235] --- Loss: 0.002\n","      - Iteration [  170 /   235] --- Loss: 0.002\n","      - Iteration [  180 /   235] --- Loss: 0.003\n","      - Iteration [  190 /   235] --- Loss: 0.002\n","      - Iteration [  200 /   235] --- Loss: 0.002\n","      - Iteration [  210 /   235] --- Loss: 0.002\n","      - Iteration [  220 /   235] --- Loss: 0.002\n","      - Iteration [  230 /   235] --- Loss: 0.003\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OA7vVKkqonOL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}